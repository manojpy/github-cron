name: Build & Push GHCR

on:
  push:
    branches: [main]
    paths: ['requirements.txt', 'Dockerfile', 'src/**', 'wrapper.py', 'config_macd.json']
  workflow_dispatch:

env:
  IMAGE_NAME: ghcr.io/${{ github.repository }}/trading-bot

jobs:
  validate:
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@v4
      
      - name: Syntax Check
        run: |
          # Check all Python files except the AOT compilation script (needs special env)
          find . -name "*.py" ! -path "./src/compile_numba_aot.py" -exec python3 -m py_compile {} + &
          python3 -c "import json; json.load(open('config_macd.json'))" &
          wait
          echo "‚úÖ All files validated"

  build:
    needs: validate
    runs-on: ubuntu-24.04
    permissions: { contents: read, packages: write }
    concurrency:
      group: trading-bot-build
      cancel-in-progress: true
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Warm up base image
        run: docker pull python:3.11-slim-bookworm

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.IMAGE_NAME }}
          tags: |
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and Push
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64
          provenance: true
          sbom: true

      - name: Verify image size
        run: |
          docker pull ${{ env.IMAGE_NAME }}:latest
          SIZE_MB=$(docker inspect ${{ env.IMAGE_NAME }}:latest --format='{{.Size}}' | awk '{print $1/1024/1024}')
          echo "üì¶ Image size: ${SIZE_MB} MB"
          
          # Warn if image is larger than expected
          SIZE_MB_INT=$(printf "%.0f" "$SIZE_MB")
          if [ "$SIZE_MB_INT" -gt 1000 ]; then
            echo "‚ö†Ô∏è WARNING: Image size (${SIZE_MB} MB) is larger than expected (should be <1GB)"
          fi

      - name: Verify AOT Cache in Built Image
        run: |
          echo "üîç Inspecting built image for AOT cache..."
          echo ""
          
          # Check if cache directory exists
          echo "üìÇ Checking cache directory existence:"
          docker run --rm ${{ env.IMAGE_NAME }}:latest sh -c \
            "if [ -d /app/src/__pycache__ ]; then \
               echo '‚úÖ Cache directory exists'; \
             else \
               echo '‚ùå Cache directory missing'; \
               exit 1; \
             fi"
          
          echo ""
          echo "üìä Cache directory contents:"
          docker run --rm ${{ env.IMAGE_NAME }}:latest sh -c \
            "ls -lah /app/src/__pycache__/ 2>/dev/null | head -20"
          
          echo ""
          echo "üì¶ Cache file count by type:"
          docker run --rm ${{ env.IMAGE_NAME }}:latest sh -c \
            "echo '  .nbi files (compiled functions):' && \
             find /app/src/__pycache__ -name '*.nbi' 2>/dev/null | wc -l && \
             echo '  .nbc files (bytecode):' && \
             find /app/src/__pycache__ -name '*.nbc' 2>/dev/null | wc -l && \
             echo '  .npz files (data):' && \
             find /app/src/__pycache__ -name '*.npz' 2>/dev/null | wc -l"
          
          echo ""
          echo "üìÇ Sample cache files (.nbi):"
          docker run --rm ${{ env.IMAGE_NAME }}:latest sh -c \
            "find /app/src/__pycache__ -name '*.nbi' 2>/dev/null | head -5 || echo '  (none found)'"
          
          echo ""
          echo "üìÇ Sample cache files (.nbc):"
          docker run --rm ${{ env.IMAGE_NAME }}:latest sh -c \
            "find /app/src/__pycache__ -name '*.nbc' 2>/dev/null | head -5 || echo '  (none found)'"
          
          echo ""
          echo "üíæ Total cache size:"
          docker run --rm ${{ env.IMAGE_NAME }}:latest sh -c \
            "du -sh /app/src/__pycache__ 2>/dev/null || echo '  (unable to calculate)'"
          
          echo ""
          echo "üîç Validation check:"
          TOTAL_CACHE_FILES=$(docker run --rm ${{ env.IMAGE_NAME }}:latest sh -c \
            "find /app/src/__pycache__ -type f \( -name '*.nbi' -o -name '*.nbc' \) 2>/dev/null | wc -l")
          
          echo "Total cache files: $TOTAL_CACHE_FILES"
          
          if [ "$TOTAL_CACHE_FILES" -lt 15 ]; then
            echo "‚ùå ERROR: Expected at least 15 cache files, found only $TOTAL_CACHE_FILES"
            echo "‚ö†Ô∏è  AOT compilation may have failed. Check build logs for 'compile_numba_aot.py' output."
            exit 1
          else
            echo "‚úÖ Cache validation passed ($TOTAL_CACHE_FILES >= 15 files)"
          fi

      - name: Test cache accessibility at runtime
        run: |
          echo "üß™ Testing Numba cache accessibility..."
          docker run --rm \
            -e TELEGRAM_BOT_TOKEN="000000:AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA" \
            -e TELEGRAM_CHAT_ID="000000000" \
            -e REDIS_URL="redis://localhost:6379" \
            -e DELTA_API_BASE="https://api.delta.exchange" \
            ${{ env.IMAGE_NAME }}:latest \
            python -c "
import os
from pathlib import Path
cache_dir = Path('/app/src/__pycache__')
if not cache_dir.exists():
    print('‚ùå Cache directory not accessible at runtime')
    exit(1)
cache_files = list(cache_dir.rglob('*.nbi')) + list(cache_dir.rglob('*.nbc'))
print(f'‚úÖ Runtime cache check: {len(cache_files)} files accessible')
if len(cache_files) < 15:
    print(f'‚ö†Ô∏è  WARNING: Only {len(cache_files)} files found (expected >= 15)')
    exit(1)
" || exit 1

      - name: Build summary
        run: |
          echo "## üì¶ Build Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          SIZE_MB=$(docker inspect ${{ env.IMAGE_NAME }}:latest --format='{{.Size}}' | awk '{print $1/1024/1024}')
          echo "**Image Size:** ${SIZE_MB} MB" >> $GITHUB_STEP_SUMMARY
          
          TOTAL_CACHE=$(docker run --rm ${{ env.IMAGE_NAME }}:latest sh -c \
            "find /app/src/__pycache__ -type f \( -name '*.nbi' -o -name '*.nbc' \) 2>/dev/null | wc -l")
          echo "**AOT Cache Files:** $TOTAL_CACHE" >> $GITHUB_STEP_SUMMARY
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Tags:**" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "${{ steps.meta.outputs.tags }}" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ "$TOTAL_CACHE" -ge 15 ]; then
            echo "‚úÖ **AOT Cache:** Verified and ready" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è **AOT Cache:** Incomplete ($TOTAL_CACHE files)" >> $GITHUB_STEP_SUMMARY
          fi